{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "import py_crepe\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "import data\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.random.seed(0123)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "subset = None\n",
    "\n",
    "#Whether to save model parameters\n",
    "save = False\n",
    "model_name_path = 'params/crepe_model.json'\n",
    "model_weights_path = 'params/crepe_model_weights.h5'\n",
    "\n",
    "#Maximum length. Longer gets chopped. Shorter gets padded.\n",
    "maxlen = 1014\n",
    "\n",
    "#Model params\n",
    "#Filters for conv layers\n",
    "nb_filter = 256\n",
    "#Number of units in the dense layer\n",
    "dense_outputs = 50\n",
    "\n",
    "#Conv layer kernel size\n",
    "filter_kernels = [7, 7, 3, 3, 3, 3]\n",
    "#Number of units in the final output layer. Number of classes.\n",
    "\n",
    "#Compile/fit params\n",
    "batch_size = 90\n",
    "nb_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "(391572, 12)\n",
      "Min: 390\n",
      "Max: 3108\n",
      "(391480, 12)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "#Expect x to be a list of sentences. Y to be a one-hot encoding of the\n",
    "#categories.\n",
    "\n",
    "authorlist=[114, 1680, 4264, 1228, 8117]\n",
    "doc_id = 2032\n",
    "cat_output = len(authorlist) #binary in the last layer\n",
    "\n",
    "# def main(authorlist, doc_id):\n",
    "    \n",
    "    \n",
    "((trainX, trainY), (valX, valY), authorlist) = data_helpers.load_ag_data(authors = authorlist, docID = doc_id)\n",
    "\n",
    "\n",
    "#trainX = data_helpers.encode_data(trainX, maxlen, vocab, vocab_size, check)\n",
    "#test_data = data_helpers.encode_data(valX, maxlen, vocab, vocab_size, check)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "classes = len(authorlist)\n",
    "\n",
    "model = py_crepe.model(dense_outputs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/anaconda2/lib/python2.7/site-packages/keras/models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4111 samples, validate on 1762 samples\n",
      "Epoch 1/30\n",
      "2760/4111 [===================>..........] - ETA: 0s - loss: 8.8281 - acc: 0.4261Epoch 00000: val_acc improved from -inf to 0.53348, saving model to author-cnn-ngrams-word.hdf5\n",
      "4111/4111 [==============================] - 0s - loss: 8.7568 - acc: 0.4342 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 2/30\n",
      "2930/4111 [====================>.........] - ETA: 0s - loss: 8.5826 - acc: 0.4543Epoch 00001: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.4543 - acc: 0.4631 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 3/30\n",
      "2960/4111 [====================>.........] - ETA: 0s - loss: 8.5456 - acc: 0.4557Epoch 00002: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.5646 - acc: 0.4534 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 4/30\n",
      "2970/4111 [====================>.........] - ETA: 0s - loss: 8.4519 - acc: 0.4609Epoch 00003: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.4672 - acc: 0.4593 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 5/30\n",
      "2950/4111 [====================>.........] - ETA: 0s - loss: 8.7277 - acc: 0.4441Epoch 00004: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.6143 - acc: 0.4510 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 6/30\n",
      "2930/4111 [====================>.........] - ETA: 0s - loss: 8.3482 - acc: 0.4601Epoch 00005: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.4194 - acc: 0.4576 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 7/30\n",
      "2970/4111 [====================>.........] - ETA: 0s - loss: 8.4936 - acc: 0.4579Epoch 00006: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.5220 - acc: 0.4563 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 8/30\n",
      "2980/4111 [====================>.........] - ETA: 0s - loss: 8.4191 - acc: 0.4638Epoch 00007: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.5254 - acc: 0.4576 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 9/30\n",
      "2980/4111 [====================>.........] - ETA: 0s - loss: 8.3612 - acc: 0.4638Epoch 00008: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.4612 - acc: 0.4576 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 10/30\n",
      "2990/4111 [====================>.........] - ETA: 0s - loss: 8.5613 - acc: 0.4525Epoch 00009: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.5047 - acc: 0.4561 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 11/30\n",
      "2980/4111 [====================>.........] - ETA: 0s - loss: 8.3432 - acc: 0.4678Epoch 00010: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.4185 - acc: 0.4624 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 12/30\n",
      "2980/4111 [====================>.........] - ETA: 0s - loss: 8.5811 - acc: 0.4503Epoch 00011: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.5489 - acc: 0.4534 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 13/30\n",
      "2980/4111 [====================>.........] - ETA: 0s - loss: 9.0320 - acc: 0.4305Epoch 00012: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 8.9372 - acc: 0.4374 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 14/30\n",
      "2940/4111 [====================>.........] - ETA: 0s - loss: 9.1572 - acc: 0.4255Epoch 00013: val_acc did not improve\n",
      "4111/4111 [==============================] - 0s - loss: 9.1399 - acc: 0.4264 - val_loss: 7.5193 - val_acc: 0.5335\n",
      "Epoch 15/30\n",
      "1490/4111 [=========>....................] - ETA: 0s - loss: 8.9027 - acc: 0.4396"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath=\"author-cnn-ngrams-word.hdf5\"\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Function to take input of data and return fitted model\n",
    "history = model.fit(trainX, trainY, validation_data=(valX, valY), nb_epoch=30, batch_size=10, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights from the best checkpoint\n",
    "model.load_weights(filepath)\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "# Compile model again (required to make predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_acc = (model.evaluate(trainX, trainY))[1]\n",
    "print(\"\\n\\nFinal Train Accuracy: %.2f\" % (train_acc * 100))\n",
    "\n",
    "val_acc = (model.evaluate(valX, valY))[1]\n",
    "print(\"\\nFinal Test Accuracy: %.2f\" % (val_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
